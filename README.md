# ml_class_imbalance_classifcation
Different Classifcaton algorithems and SMOTE analysis of the oil spill data set 
The Oil Spill dataset comes from the UCI Machine Learning Repository, a well-known and trusted source for datasets used in machine learning and data science research.

ğŸ” Dataset Source:
Name: Oil Spill Detection Dataset

Repository: UCI Machine Learning Repository

Original Link: https://archive.ics.uci.edu/ml/datasets/Oil+Spill

ğŸ“„ Description:
This dataset was originally used for SAR (Synthetic Aperture Radar) image analysis, to detect oil spills in the ocean. Each row in the dataset represents a segment extracted from SAR images. The attributes describe statistical and physical properties of the image segments.

Instances: 937

Features: 48 numerical attributes (like texture, contrast, etc.)

Target: 1 = Oil Spill, 0 = Look-alike (non-spill, such as ocean wave or ship)

---

# ğŸ›¢ï¸ Oil Spill Dataset: Analysis & Classification Modeling Report

## ğŸ“Š Dataset Overview

The dataset comprises **937 rows and 48 columns**, with the objective of predicting oil spills. The **target variable (`Target`)** is binary (0 or 1), indicating whether an oil spill occurred. The dataset includes a mix of numerical and categorical variables.

### âœ… Key Characteristics:
- **Target Type**: Binary classification (0 or 1)
- **No Missing Values**: Dataset is complete
- **Class Imbalance**: Present â€” addressed with **SMOTE** (Synthetic Minority Oversampling Technique)

---

## ğŸ§¹ Data Preprocessing

1. **Column Renaming**: All columns were renamed to `col_0` through `col_49` for clarity.
2. **Target Separation**: The `Target` column was isolated from the features.
3. **Feature Scaling**: All features were scaled using **StandardScaler**.
4. **Imbalance Correction**: SMOTE was applied to balance the class distribution and improve model performance.

---

## ğŸ“ˆ Exploratory Data Analysis (EDA)

### ğŸ§® Basic Insights:
- **Descriptive Stats**: Summary stats via `df.describe()` and structure using `df.info()`
- **Duplicates Check**: Identified and counted
- **Unique Values**: Counted across each column

### ğŸ“Š Visualizations:
- **Count Plot**: Distribution of the target classes
- **Histograms**: Distribution of individual features
- **Violin Plots**: Feature distributions with respect to the target
- **Correlation Heatmap**: Relationships between features

---

## ğŸ¤– Machine Learning Models

A variety of classification models were applied, each evaluated for accuracy. Both default and custom hyperparameters were tested.

### 1. **Logistic Regression**
Tested with four solvers:
- `liblinear` â†’ â­ **Best: 97.52%**
- `newton-cg`, `newton-cholesky`, `saga`

### 2. **K-Nearest Neighbors (KNN)**
- Configurations tested with different neighbors and algorithms:
  - Best: **89.36%** using `n_neighbors=10`, `algorithm='brute'`

### 3. **Decision Tree**
- Two splits evaluated:
  - Best: **94.68%** using `criterion='gini'`

### 4. **Random Forest**
- Estimators and criteria varied:
  - Best: **95.74%** with `n_estimators=150`, `criterion='entropy'`

---

## ğŸ“Š Model Comparison Summary

| Model                         | Hyperparameters and parameters Tuning                                      | Accuracy Score | SMOTE Used |
|-----------------------------|------------------------------------------------------------------------------|----------------|------------|
| **Logistic Regression (lr1)** | `penalty='l2', solver='liblinear'`                                         | 92.19%     | âœ… Yes       |
| Logistic Regression (lr2)     | `penalty='l2', solver='newton-cg'`                                         | 92.55%         | âœ… Yes        |
| Logistic Regression (lr3)     | `penalty='l2', solver='newton-cholesky'`                                   | 92.55%         | âœ… Yes       |
| Logistic Regression (lr4)     | `penalty='elasticnet', solver='saga', l1_ratio=0.5`                        | 91.13%         | âœ… Yes       |
| KNN (knn1)                    | `n_neighbors=30, algorithm='ball_tree'`                                    | 77.66%         | âœ… Yes      |
| KNN (knn2)                    | `n_neighbors=10, algorithm='brute'`                                        | 89.36%         | âœ… Yes      |
| Decision Tree (dtc1)          | `criterion='entropy', splitter='random'`                                   | 91.84%         | âœ… Yes      |
| **Decision Tree (dtc2)**      | `criterion='gini', splitter='best'`                                        | **94.68%**     | âœ… Yes      |
| **Random Forest (rfc_1)**     | `n_estimators=150, criterion='entropy'`                                    | **95.74%**     | âœ… Yes      |
| Random Forest (rfc_2)         | `n_estimators=100, criterion='gini'`                                       | 95.39%         | âœ… Yes      |

---

## ğŸ§¾ Conclusion

- **Random Forest** and **Decision Tree** showed strong results with **SMOTE applied**, at **95.74%** and **94.68%**, respectively.
- SMOTE was **effective** in improving the performance of models sensitive to class imbalance like **KNN** and **Decision Trees**.

---

## ğŸ’¡ Recommendations

1. **Feature Selection**: Perform further analysis to identify redundant or low-impact features.
2. **Hyperparameter Optimization**: Use **GridSearchCV** or **RandomizedSearchCV** for fine-tuning.
3. **Ensemble Approaches**: Consider advanced ensemble techniques like **Stacking**, **Voting**, or **Boosting** for potentially higher accuracy.
4. **Model Explainability**: Apply SHAP or LIME to understand feature contributions for more transparent decisions.

---
---
â€‹The Oil Spill Detection dataset is available through the UCI Machine Learning Repository, a widely recognized resource for machine learning datasets. This dataset was introduced in the 1998 paper by Miroslav Kubat et al., titled "Machine Learning for the Detection of Oil Spills in Satellite Radar Images." It comprises 937 instances with 48 numerical features derived from satellite radar images, aimed at classifying regions as containing oil spills or not.â€‹

ğŸ“„ License Information
The UCI Machine Learning Repository does not enforce a universal license across all its datasets. Licensing terms can vary depending on the dataset's contributor. For the Oil Spill Detection dataset, specific licensing details are not explicitly provided on the UCI website. In such cases, it is generally understood that the dataset is intended for research and educational purposes. However, for any commercial use, it's advisable to contact the original authors or the UCI repository maintainers to obtain appropriate permissions.â€‹

ğŸ“Œ Citation

Kubat, M., Holte, R., & Matwin, S. (1998). Machine Learning for the Detection of Oil Spills in Satellite Radar Images. Machine Learning, 30(2-3), 195â€“215.â€‹

This citation acknowledges the original creators and supports the academic use of the dataset.
---
